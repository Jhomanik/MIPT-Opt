{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#  Стохастические градиентные методы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Постановка задачи\n",
    "\n",
    "$$\n",
    "\\min_x \\frac1N \\sum_{i=1}^N f_i(x)\n",
    "$$\n",
    "\n",
    "- Целевая функция - сумма конечного числа функций\n",
    "- $N$ может быть очень большим"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Особенности задачи\n",
    "\n",
    "- Точное вычисление градиента занимает очень много времени\n",
    "- Высокая точность решения обычно не требуется\n",
    "- Допустимо введение случайности"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Использование структуры функции\n",
    "\n",
    "- Так как целевая функция равна сумме функций, то градиент равен сумме градиентов\n",
    "- **Основная идея:** вместо сложения всех градиентов, сложить только некоторые, выбранные некотором образом\n",
    "- Как выбирать?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Стохастический градиентный спуск (SGD)\n",
    "\n",
    "$$\n",
    "x_{k+1} = x_k - \\alpha_k \\sum_{i \\in \\mathcal{I}} f'_i(x_k)\n",
    "$$\n",
    "\n",
    "Сходимость\n",
    "\n",
    "- Для выпуклых функций $\\mathcal{O}(1 / \\sqrt{k})$\n",
    "- Для сильно выпуклых функций $\\mathcal{O}(1 / k)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Ускоренный градиентный метод\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "& h_k = \\beta h_{k-1} - \\alpha_k \\sum_{i\\in \\mathcal{I}} f'_i(x_k + \\alpha_k h_k)\\\\\n",
    "& x_{k+1} = x_k + h_k\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "- Не приводит к ускорению в теории!\n",
    "- Почему?\n",
    "- Различные реализации в различных пакетах могут называться одинаково"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Adagrad\n",
    "\n",
    "\\begin{align*}\n",
    "& g_k = \\sum_{i \\in \\mathcal{I}} f'_i(x_k)\\\\\n",
    "& r = r + g_k \\cdot g_k\\\\\n",
    "& h_k = -\\frac{\\varepsilon}{\\delta + \\sqrt{r}} \\cdot g_k\\\\\n",
    "& x_{k+1} = x_k + h_k\n",
    "\\end{align*}\n",
    "\n",
    "- Диагональное шкалирование градиента\n",
    "- Учёт **всей** предыдущей истории для вычисления следующей точки\n",
    "- Не улучшает теоретические оценки сходимости"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Adam\n",
    "\n",
    "\\begin{align*}\n",
    "& g_k = \\sum_{i \\in \\mathcal{I}} f'_i(x_k)\\\\\n",
    "& r = \\rho_2r + (1 - \\rho_2) g_k \\cdot g_k\\\\\n",
    "& s = \\rho_1 s + (1 - \\rho_1) g_k\\\\\n",
    "& \\hat{s} = \\frac{s}{1 - \\rho_1^k}\\\\\n",
    "& \\hat{r} = \\frac{r}{1 - \\rho_2^k}\\\\\n",
    "& h_k = -\\frac{\\varepsilon \\hat{s}}{\\delta + \\sqrt{\\hat{r}}} \\\\\n",
    "& x_{k+1} = x_k + h_k\n",
    "\\end{align*}\n",
    "\n",
    "- Все операции выполняются поэлементно"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Другие модификации\n",
    "\n",
    "<img src=\"optax_common.png\" width=400>\n",
    "\n",
    "- Список взят из документации к [optax](https://optax.readthedocs.io/en/latest/)\n",
    "- Как вы думаете, что можно улучшать в рассмотренных выше методах?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Основные направления улучшений\n",
    "\n",
    "- Настройка размера шага\n",
    "- Использование дополнительного шума для избегания локальных минимумов\n",
    "- Сокращение дополнительной памяти"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Выводы\n",
    "\n",
    "- Использование знания о структуре функции позволяет ускорить процесс вычисления градиента\n",
    "- За это приходится платить снижением точности\n",
    "- Адаптивные размеры шага генерируются на основании истории вычисленных градиентов\n",
    "- Иногда адекватно работают и для невыпуклых функций\n",
    "- Ускоренные методы работают на практике гораздо лучше, чем в теории"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
