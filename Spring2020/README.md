# Spring term 2020

1. Intro to numerical optimization methods. Gradient descent ([ru](./Spring2020/intro_gd.ipynb), en)

2. How to accelerate gradient descent: conjugate gradient method, heavy-ball method and fast gradient method ([ru](./Spring2020/acc_grad.ipynb), en)

3. Second order methods: Newton method. Quasi-Newton methods as trade-off between convergence speed and cost of one iterations ([ru](./Spring2020/newton_quasi.ipynb), en)

4. Non-smooth optimization problems: subgradient methods and intro to proximal methods ([ru](./Spring2020/subgrad_prox.ipynb), en)

5. Least squares problem: matrix factorizations and Levenberg-Marquardt algorithm ([ru](./Spring2020/lsq.ipynb), en)

6. Smoothing: smooth minimization of non-smooth functions ([original paper](https://link.springer.com/article/10.1007/s10107-004-0552-5))  ([ru](./Spring2020/smoothing.ipynb), en)

7. Simple constrained optimization peroblems: projected gradient method and Frank-Wolfe method ([ru](./Spring2020/pg_fw.ipynb), en)

8. General purpose solvers: interior point methods ([ru](./Spring2020/int_point.ipynb), en)

9. How to parallel optimization methods: penalty method, augmented Lagrangian method and ADMM ([ru](./Spring2020/penalty_admm.ipynb), en)
